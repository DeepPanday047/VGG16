{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPEzF6ew5JItUseRn1CcZhC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import tensorflow as tf \n","from tensorflow import keras\n","from keras.datasets import cifar10\n","from keras.models import Model\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.utils import to_categorical\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications.vgg16 import VGG16"],"metadata":{"id":"p4NTW3fQramx","executionInfo":{"status":"ok","timestamp":1680533265700,"user_tz":-330,"elapsed":2189,"user":{"displayName":"Deep Panday","userId":"09721463098306661326"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Load the dataset\n","\n","(x_train,y_train) , (x_test,y_test) = cifar10.load_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fBbEXB70r_Ok","executionInfo":{"status":"ok","timestamp":1680533275892,"user_tz":-330,"elapsed":10201,"user":{"displayName":"Deep Panday","userId":"09721463098306661326"}},"outputId":"9426ac19-ba21-48d7-b6b8-1bf55cdce873"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 6s 0us/step\n"]}]},{"cell_type":"code","source":["# Preprocess the images\n","x_train = x_train.astype('float32') / 255.0\n","x_test= x_test.astype('float32') / 255.0\n","\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n"],"metadata":{"id":"8iZS98xFsTR5","executionInfo":{"status":"ok","timestamp":1680533275894,"user_tz":-330,"elapsed":13,"user":{"displayName":"Deep Panday","userId":"09721463098306661326"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Define the VGG16 model with the last layer removed\n","vgg16 = VGG16(include_top=False,input_shape=(32,32,3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wd_OzVi3stLf","executionInfo":{"status":"ok","timestamp":1680533284142,"user_tz":-330,"elapsed":8258,"user":{"displayName":"Deep Panday","userId":"09721463098306661326"}},"outputId":"b2bd42cf-a0b0-4152-ed72-6769fbb1da86"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 2s 0us/step\n"]}]},{"cell_type":"code","source":["from keras.layers.attention.multi_head_attention import activation\n","flatten = Flatten()(vgg16.output)\n","dense1 = Dense(4096,activation='relu')(flatten)\n","dense2 = Dense(4096,activation='relu')(dense1)\n","output = Dense(10,activation='softmax')(dense2)\n"],"metadata":{"id":"riLpqIFfu_e9","executionInfo":{"status":"ok","timestamp":1680533284143,"user_tz":-330,"elapsed":59,"user":{"displayName":"Deep Panday","userId":"09721463098306661326"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model = Model(inputs=vgg16.input,outputs=output)"],"metadata":{"id":"TEdzdFRpyB0I","executionInfo":{"status":"ok","timestamp":1680533284145,"user_tz":-330,"elapsed":58,"user":{"displayName":"Deep Panday","userId":"09721463098306661326"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["for layer in vgg16.layers:\n","  layer.trainable = False"],"metadata":{"id":"tWEd06JkyR2g","executionInfo":{"status":"ok","timestamp":1680533284147,"user_tz":-330,"elapsed":59,"user":{"displayName":"Deep Panday","userId":"09721463098306661326"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R1U7ljPDyaEI","executionInfo":{"status":"ok","timestamp":1680533284148,"user_tz":-330,"elapsed":59,"user":{"displayName":"Deep Panday","userId":"09721463098306661326"}},"outputId":"04642b13-dd0a-4e43-818c-8c9edbda0242"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 4096)              2101248   \n","                                                                 \n"," dense_1 (Dense)             (None, 4096)              16781312  \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                40970     \n","                                                                 \n","=================================================================\n","Total params: 33,638,218\n","Trainable params: 18,923,530\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# model compile"],"metadata":{"id":"oB_Ryilt16VZ"}},{"cell_type":"code","source":["model.compile(optimizer=SGD(learning_rate=0.001),loss='categorical_crossentropy',metrics=['acc'])"],"metadata":{"id":"xvC8gvvAyfRJ","executionInfo":{"status":"ok","timestamp":1680533285594,"user_tz":-330,"elapsed":1477,"user":{"displayName":"Deep Panday","userId":"09721463098306661326"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Data augmentation"],"metadata":{"id":"BHLyOTlt2DIz"}},{"cell_type":"code","source":["datagen = ImageDataGenerator(\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True,\n","    vertical_flip=False,\n","    zoom_range=[0.9,1.1],\n","    fill_mode='constant',\n","    cval=0.0\n",")"],"metadata":{"id":"VA-Yq1az2Clv","executionInfo":{"status":"ok","timestamp":1680533285595,"user_tz":-330,"elapsed":8,"user":{"displayName":"Deep Panday","userId":"09721463098306661326"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Train the model"],"metadata":{"id":"FiB0HiGS2oD_"}},{"cell_type":"code","source":["history = model.fit(datagen.flow(x_train,y_train,batch_size=128),epochs=100,validation_data=(x_test,y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EPtCLUAS2mUi","executionInfo":{"status":"ok","timestamp":1680536791959,"user_tz":-330,"elapsed":552497,"user":{"displayName":"Deep Panday","userId":"09721463098306661326"}},"outputId":"7659d0aa-b6d5-4b05-b2a0-5a0e031dc66f"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","391/391 [==============================] - 43s 87ms/step - loss: 2.2495 - acc: 0.2223 - val_loss: 2.2121 - val_acc: 0.2654\n","Epoch 2/100\n","391/391 [==============================] - 33s 84ms/step - loss: 2.1648 - acc: 0.3062 - val_loss: 2.1447 - val_acc: 0.2926\n","Epoch 3/100\n","391/391 [==============================] - 34s 88ms/step - loss: 2.0962 - acc: 0.3268 - val_loss: 2.0921 - val_acc: 0.2980\n","Epoch 4/100\n","391/391 [==============================] - 33s 84ms/step - loss: 2.0397 - acc: 0.3384 - val_loss: 2.0460 - val_acc: 0.3092\n","Epoch 5/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.9906 - acc: 0.3457 - val_loss: 2.0065 - val_acc: 0.3194\n","Epoch 6/100\n","391/391 [==============================] - 34s 86ms/step - loss: 1.9475 - acc: 0.3538 - val_loss: 1.9712 - val_acc: 0.3260\n","Epoch 7/100\n","391/391 [==============================] - 33s 83ms/step - loss: 1.9112 - acc: 0.3598 - val_loss: 1.9439 - val_acc: 0.3286\n","Epoch 8/100\n","391/391 [==============================] - 33s 85ms/step - loss: 1.8813 - acc: 0.3631 - val_loss: 1.9117 - val_acc: 0.3389\n","Epoch 9/100\n","391/391 [==============================] - 32s 83ms/step - loss: 1.8558 - acc: 0.3697 - val_loss: 1.8839 - val_acc: 0.3432\n","Epoch 10/100\n","391/391 [==============================] - 33s 85ms/step - loss: 1.8281 - acc: 0.3761 - val_loss: 1.8657 - val_acc: 0.3483\n","Epoch 11/100\n","391/391 [==============================] - 33s 83ms/step - loss: 1.8076 - acc: 0.3803 - val_loss: 1.8460 - val_acc: 0.3512\n","Epoch 12/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.7865 - acc: 0.3858 - val_loss: 1.8208 - val_acc: 0.3609\n","Epoch 13/100\n","391/391 [==============================] - 33s 84ms/step - loss: 1.7670 - acc: 0.3880 - val_loss: 1.8093 - val_acc: 0.3618\n","Epoch 14/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.7493 - acc: 0.3933 - val_loss: 1.7885 - val_acc: 0.3666\n","Epoch 15/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.7359 - acc: 0.3960 - val_loss: 1.7832 - val_acc: 0.3624\n","Epoch 16/100\n","391/391 [==============================] - 33s 84ms/step - loss: 1.7210 - acc: 0.4028 - val_loss: 1.7613 - val_acc: 0.3716\n","Epoch 17/100\n","391/391 [==============================] - 32s 83ms/step - loss: 1.7123 - acc: 0.4011 - val_loss: 1.7532 - val_acc: 0.3703\n","Epoch 18/100\n","391/391 [==============================] - 33s 84ms/step - loss: 1.6963 - acc: 0.4058 - val_loss: 1.7384 - val_acc: 0.3789\n","Epoch 19/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.6875 - acc: 0.4088 - val_loss: 1.7331 - val_acc: 0.3762\n","Epoch 20/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.6814 - acc: 0.4088 - val_loss: 1.7239 - val_acc: 0.3822\n","Epoch 21/100\n","391/391 [==============================] - 33s 84ms/step - loss: 1.6734 - acc: 0.4112 - val_loss: 1.7131 - val_acc: 0.3880\n","Epoch 22/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.6587 - acc: 0.4177 - val_loss: 1.7068 - val_acc: 0.3869\n","Epoch 23/100\n","391/391 [==============================] - 33s 84ms/step - loss: 1.6581 - acc: 0.4151 - val_loss: 1.7010 - val_acc: 0.3868\n","Epoch 24/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.6504 - acc: 0.4200 - val_loss: 1.6890 - val_acc: 0.3942\n","Epoch 25/100\n","391/391 [==============================] - 32s 83ms/step - loss: 1.6413 - acc: 0.4216 - val_loss: 1.6830 - val_acc: 0.4002\n","Epoch 26/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.6340 - acc: 0.4220 - val_loss: 1.6836 - val_acc: 0.3973\n","Epoch 27/100\n","391/391 [==============================] - 32s 83ms/step - loss: 1.6286 - acc: 0.4266 - val_loss: 1.6827 - val_acc: 0.3978\n","Epoch 28/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.6233 - acc: 0.4261 - val_loss: 1.6755 - val_acc: 0.3999\n","Epoch 29/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.6163 - acc: 0.4300 - val_loss: 1.6677 - val_acc: 0.4020\n","Epoch 30/100\n","391/391 [==============================] - 31s 79ms/step - loss: 1.6153 - acc: 0.4270 - val_loss: 1.6719 - val_acc: 0.3996\n","Epoch 31/100\n","391/391 [==============================] - 32s 83ms/step - loss: 1.6092 - acc: 0.4291 - val_loss: 1.6635 - val_acc: 0.4046\n","Epoch 32/100\n","391/391 [==============================] - 31s 80ms/step - loss: 1.6039 - acc: 0.4332 - val_loss: 1.6520 - val_acc: 0.4091\n","Epoch 33/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.5988 - acc: 0.4351 - val_loss: 1.6495 - val_acc: 0.4087\n","Epoch 34/100\n","391/391 [==============================] - 31s 79ms/step - loss: 1.5936 - acc: 0.4350 - val_loss: 1.6535 - val_acc: 0.4069\n","Epoch 35/100\n","391/391 [==============================] - 33s 84ms/step - loss: 1.5947 - acc: 0.4354 - val_loss: 1.6435 - val_acc: 0.4141\n","Epoch 36/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.5884 - acc: 0.4390 - val_loss: 1.6432 - val_acc: 0.4130\n","Epoch 37/100\n","391/391 [==============================] - 33s 83ms/step - loss: 1.5802 - acc: 0.4417 - val_loss: 1.6441 - val_acc: 0.4124\n","Epoch 38/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.5819 - acc: 0.4401 - val_loss: 1.6405 - val_acc: 0.4117\n","Epoch 39/100\n","391/391 [==============================] - 33s 85ms/step - loss: 1.5747 - acc: 0.4420 - val_loss: 1.6386 - val_acc: 0.4123\n","Epoch 40/100\n","391/391 [==============================] - 35s 89ms/step - loss: 1.5722 - acc: 0.4437 - val_loss: 1.6355 - val_acc: 0.4151\n","Epoch 41/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.5675 - acc: 0.4453 - val_loss: 1.6297 - val_acc: 0.4165\n","Epoch 42/100\n","391/391 [==============================] - 33s 84ms/step - loss: 1.5658 - acc: 0.4427 - val_loss: 1.6273 - val_acc: 0.4161\n","Epoch 43/100\n","391/391 [==============================] - 31s 80ms/step - loss: 1.5627 - acc: 0.4465 - val_loss: 1.6199 - val_acc: 0.4209\n","Epoch 44/100\n","391/391 [==============================] - 33s 83ms/step - loss: 1.5625 - acc: 0.4443 - val_loss: 1.6149 - val_acc: 0.4234\n","Epoch 45/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.5571 - acc: 0.4492 - val_loss: 1.6178 - val_acc: 0.4204\n","Epoch 46/100\n","391/391 [==============================] - 33s 83ms/step - loss: 1.5535 - acc: 0.4467 - val_loss: 1.6181 - val_acc: 0.4219\n","Epoch 47/100\n","391/391 [==============================] - 33s 84ms/step - loss: 1.5571 - acc: 0.4477 - val_loss: 1.6136 - val_acc: 0.4211\n","Epoch 48/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.5506 - acc: 0.4498 - val_loss: 1.6116 - val_acc: 0.4232\n","Epoch 49/100\n","391/391 [==============================] - 33s 83ms/step - loss: 1.5474 - acc: 0.4517 - val_loss: 1.6059 - val_acc: 0.4260\n","Epoch 50/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.5422 - acc: 0.4533 - val_loss: 1.6043 - val_acc: 0.4228\n","Epoch 51/100\n","391/391 [==============================] - 32s 83ms/step - loss: 1.5422 - acc: 0.4550 - val_loss: 1.6018 - val_acc: 0.4268\n","Epoch 52/100\n","391/391 [==============================] - 31s 80ms/step - loss: 1.5372 - acc: 0.4555 - val_loss: 1.6007 - val_acc: 0.4265\n","Epoch 53/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.5328 - acc: 0.4536 - val_loss: 1.5973 - val_acc: 0.4280\n","Epoch 54/100\n","391/391 [==============================] - 31s 80ms/step - loss: 1.5360 - acc: 0.4556 - val_loss: 1.5955 - val_acc: 0.4285\n","Epoch 55/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.5343 - acc: 0.4525 - val_loss: 1.5920 - val_acc: 0.4290\n","Epoch 56/100\n","391/391 [==============================] - 31s 80ms/step - loss: 1.5317 - acc: 0.4565 - val_loss: 1.5937 - val_acc: 0.4299\n","Epoch 57/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.5294 - acc: 0.4588 - val_loss: 1.6000 - val_acc: 0.4247\n","Epoch 58/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.5260 - acc: 0.4572 - val_loss: 1.5930 - val_acc: 0.4292\n","Epoch 59/100\n","391/391 [==============================] - 31s 79ms/step - loss: 1.5247 - acc: 0.4584 - val_loss: 1.5842 - val_acc: 0.4342\n","Epoch 60/100\n","391/391 [==============================] - 32s 83ms/step - loss: 1.5174 - acc: 0.4604 - val_loss: 1.5844 - val_acc: 0.4337\n","Epoch 61/100\n","391/391 [==============================] - 32s 83ms/step - loss: 1.5208 - acc: 0.4597 - val_loss: 1.5801 - val_acc: 0.4329\n","Epoch 62/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.5185 - acc: 0.4600 - val_loss: 1.5841 - val_acc: 0.4345\n","Epoch 63/100\n","391/391 [==============================] - 32s 83ms/step - loss: 1.5152 - acc: 0.4609 - val_loss: 1.5783 - val_acc: 0.4343\n","Epoch 64/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.5170 - acc: 0.4623 - val_loss: 1.5763 - val_acc: 0.4355\n","Epoch 65/100\n","391/391 [==============================] - 31s 80ms/step - loss: 1.5152 - acc: 0.4628 - val_loss: 1.5781 - val_acc: 0.4346\n","Epoch 66/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.5174 - acc: 0.4631 - val_loss: 1.5748 - val_acc: 0.4373\n","Epoch 67/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.5099 - acc: 0.4632 - val_loss: 1.5747 - val_acc: 0.4357\n","Epoch 68/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.5075 - acc: 0.4664 - val_loss: 1.5774 - val_acc: 0.4338\n","Epoch 69/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.5060 - acc: 0.4662 - val_loss: 1.5740 - val_acc: 0.4352\n","Epoch 70/100\n","391/391 [==============================] - 33s 83ms/step - loss: 1.5053 - acc: 0.4667 - val_loss: 1.5781 - val_acc: 0.4317\n","Epoch 71/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.5035 - acc: 0.4699 - val_loss: 1.5666 - val_acc: 0.4398\n","Epoch 72/100\n","391/391 [==============================] - 32s 83ms/step - loss: 1.5000 - acc: 0.4678 - val_loss: 1.5610 - val_acc: 0.4403\n","Epoch 73/100\n","391/391 [==============================] - 31s 80ms/step - loss: 1.5030 - acc: 0.4675 - val_loss: 1.5709 - val_acc: 0.4361\n","Epoch 74/100\n","391/391 [==============================] - 33s 83ms/step - loss: 1.4993 - acc: 0.4684 - val_loss: 1.5627 - val_acc: 0.4387\n","Epoch 75/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.4993 - acc: 0.4683 - val_loss: 1.5642 - val_acc: 0.4400\n","Epoch 76/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.4961 - acc: 0.4693 - val_loss: 1.5602 - val_acc: 0.4406\n","Epoch 77/100\n","391/391 [==============================] - 33s 85ms/step - loss: 1.4943 - acc: 0.4675 - val_loss: 1.5565 - val_acc: 0.4408\n","Epoch 78/100\n","391/391 [==============================] - 33s 85ms/step - loss: 1.4964 - acc: 0.4668 - val_loss: 1.5535 - val_acc: 0.4416\n","Epoch 79/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.4936 - acc: 0.4702 - val_loss: 1.5650 - val_acc: 0.4356\n","Epoch 80/100\n","391/391 [==============================] - 32s 83ms/step - loss: 1.4886 - acc: 0.4741 - val_loss: 1.5633 - val_acc: 0.4399\n","Epoch 81/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.4891 - acc: 0.4696 - val_loss: 1.5627 - val_acc: 0.4398\n","Epoch 82/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.4875 - acc: 0.4723 - val_loss: 1.5512 - val_acc: 0.4477\n","Epoch 83/100\n","391/391 [==============================] - 30s 78ms/step - loss: 1.4888 - acc: 0.4715 - val_loss: 1.5520 - val_acc: 0.4428\n","Epoch 84/100\n","391/391 [==============================] - 31s 80ms/step - loss: 1.4874 - acc: 0.4727 - val_loss: 1.5517 - val_acc: 0.4443\n","Epoch 85/100\n","391/391 [==============================] - 31s 79ms/step - loss: 1.4886 - acc: 0.4730 - val_loss: 1.5431 - val_acc: 0.4493\n","Epoch 86/100\n","391/391 [==============================] - 31s 79ms/step - loss: 1.4859 - acc: 0.4765 - val_loss: 1.5471 - val_acc: 0.4436\n","Epoch 87/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.4847 - acc: 0.4749 - val_loss: 1.5459 - val_acc: 0.4479\n","Epoch 88/100\n","391/391 [==============================] - 31s 81ms/step - loss: 1.4859 - acc: 0.4734 - val_loss: 1.5418 - val_acc: 0.4479\n","Epoch 89/100\n","391/391 [==============================] - 31s 80ms/step - loss: 1.4792 - acc: 0.4758 - val_loss: 1.5394 - val_acc: 0.4479\n","Epoch 90/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.4800 - acc: 0.4786 - val_loss: 1.5468 - val_acc: 0.4455\n","Epoch 91/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.4781 - acc: 0.4757 - val_loss: 1.5315 - val_acc: 0.4547\n","Epoch 92/100\n","391/391 [==============================] - 31s 80ms/step - loss: 1.4745 - acc: 0.4787 - val_loss: 1.5453 - val_acc: 0.4463\n","Epoch 93/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.4791 - acc: 0.4751 - val_loss: 1.5453 - val_acc: 0.4463\n","Epoch 94/100\n","391/391 [==============================] - 32s 82ms/step - loss: 1.4749 - acc: 0.4773 - val_loss: 1.5412 - val_acc: 0.4498\n","Epoch 95/100\n","391/391 [==============================] - 31s 79ms/step - loss: 1.4732 - acc: 0.4764 - val_loss: 1.5367 - val_acc: 0.4501\n","Epoch 96/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.4740 - acc: 0.4797 - val_loss: 1.5424 - val_acc: 0.4433\n","Epoch 97/100\n","391/391 [==============================] - 32s 81ms/step - loss: 1.4734 - acc: 0.4761 - val_loss: 1.5429 - val_acc: 0.4473\n","Epoch 98/100\n","391/391 [==============================] - 31s 79ms/step - loss: 1.4697 - acc: 0.4787 - val_loss: 1.5302 - val_acc: 0.4528\n","Epoch 99/100\n","391/391 [==============================] - 31s 80ms/step - loss: 1.4766 - acc: 0.4774 - val_loss: 1.5336 - val_acc: 0.4516\n","Epoch 100/100\n","391/391 [==============================] - 30s 77ms/step - loss: 1.4713 - acc: 0.4788 - val_loss: 1.5275 - val_acc: 0.4540\n"]}]},{"cell_type":"code","source":["loss, accuracy = model.evaluate(x_test, y_test)\n","print('Test accuracy:', accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7HwpIEXp4p76","executionInfo":{"status":"ok","timestamp":1680536797436,"user_tz":-330,"elapsed":5486,"user":{"displayName":"Deep Panday","userId":"09721463098306661326"}},"outputId":"40066712-53d0-4715-eff4-8a25f547c3d2"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 3s 8ms/step - loss: 1.5275 - acc: 0.4540\n","Test accuracy: 0.45399999618530273\n"]}]}]}